Using cache found in C:\Users\mhroh/.cache\torch\hub\facebookresearch_dinov2_main
C:\Users\mhroh/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
C:\Users\mhroh/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
C:\Users\mhroh/.cache\torch\hub\facebookresearch_dinov2_main\dinov2\layers\block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
1it [00:09,  9.46s/it]
gt : tensor([[7.9506e-11, 7.9556e-11, 7.9537e-11,  ..., 7.2363e-11, 7.2365e-11,
         7.2383e-11],
        [7.9482e-11, 7.9582e-11, 7.9640e-11,  ..., 7.2647e-11, 7.2579e-11,
         7.2568e-11],
        [7.9551e-11, 7.9585e-11, 7.9677e-11,  ..., 7.2940e-11, 7.2804e-11,
         7.2762e-11],
        ...,
        [1.8607e-10, 1.8600e-10, 1.8593e-10,  ..., 1.7566e-10, 1.7563e-10,
         1.7559e-10],
        [1.8633e-10, 1.8624e-10, 1.8620e-10,  ..., 1.7593e-10, 1.7590e-10,
         1.7585e-10],
        [1.8660e-10, 1.8651e-10, 1.8647e-10,  ..., 1.7620e-10, 1.7616e-10,
         1.7612e-10]], device='cuda:0')
pred : tensor([[1.9667e-02, 2.4873e-02, 3.1153e-02,  ..., 6.1399e-02, 6.2634e-02,
         3.3860e-02],
        [3.1651e-02, 4.4436e-02, 5.2655e-02,  ..., 5.8217e-02, 5.9597e-02,
         3.1014e-02],
        [2.4775e-02, 5.6191e-02, 6.2047e-02,  ..., 5.0912e-02, 5.5754e-02,
         3.4295e-02],
        ...,
        [5.8707e-03, 1.1269e-05, 0.0000e+00,  ..., 2.4118e-02, 3.6716e-02,
         3.0386e-02],
        [9.8408e-03, 5.1419e-03, 2.6749e-04,  ..., 1.9387e-02, 3.6793e-02,
         3.4461e-02],
        [1.6275e-02, 1.4528e-02, 1.0497e-02,  ..., 8.8572e-03, 1.7447e-02,
         1.4955e-02]], device='cuda:0', grad_fn=<SelectBackward0>)
y aggregation : tensor(3.3982e-08, device='cuda:0')
pred aggregation : tensor(20.7307, device='cuda:0', grad_fn=<SumBackward1>)
Epoch [1/30], Batch [0], Loss: 1.2153
gt : tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.1734e-08, 1.1738e-08,
         1.1742e-08],
        [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.1746e-08, 1.1751e-08,
         1.1756e-08],
        [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.1758e-08, 1.1763e-08,
         1.1768e-08],
        ...,
        [7.0516e-09, 7.0515e-09, 7.0515e-09,  ..., 1.1091e-08, 1.1099e-08,
         1.1106e-08],
        [7.0625e-09, 7.0625e-09, 7.0626e-09,  ..., 1.1081e-08, 1.1089e-08,
         1.1096e-08],
        [7.0737e-09, 7.0738e-09, 7.0738e-09,  ..., 1.1071e-08, 1.1078e-08,
         1.1086e-08]], device='cuda:0')
pred : tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        ...,
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0004],
        [0.0073, 0.0048, 0.0003,  ..., 0.0000, 0.0000, 0.0034]],
       device='cuda:0', grad_fn=<SelectBackward0>)
y aggregation : tensor(209., device='cuda:0')
pred aggregation : tensor(0., device='cuda:0', grad_fn=<SumBackward1>)
gt : tensor([[1.0842e-09, 1.0850e-09, 1.0856e-09,  ..., 5.7413e-10, 5.7391e-10,
         5.7398e-10],
        [1.0850e-09, 1.0856e-09, 1.0862e-09,  ..., 5.7444e-10, 5.7446e-10,
         5.7443e-10],
        [1.0856e-09, 1.0862e-09, 1.0871e-09,  ..., 5.7468e-10, 5.7475e-10,
         5.7476e-10],
        ...,
        [7.6293e-10, 7.6304e-10, 7.6320e-10,  ..., 1.3409e-09, 1.3407e-09,
         1.3408e-09],
        [7.6356e-10, 7.6428e-10, 7.6427e-10,  ..., 1.3416e-09, 1.3415e-09,
         1.3415e-09],
        [7.6433e-10, 7.6500e-10, 7.6485e-10,  ..., 1.3423e-09, 1.3422e-09,
         1.3421e-09]], device='cuda:0')
pred : tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<SelectBackward0>)
y aggregation : tensor(4.3706e-07, device='cuda:0')
pred aggregation : tensor(0., device='cuda:0', grad_fn=<SumBackward1>)
gt : tensor([[1.1966e-09, 1.1968e-09, 1.1969e-09,  ..., 6.4321e-10, 6.4307e-10,
         6.4237e-10],
        [1.1987e-09, 1.1988e-09, 1.1988e-09,  ..., 6.4284e-10, 6.4391e-10,
         6.4449e-10],
        [1.2005e-09, 1.2004e-09, 1.2001e-09,  ..., 6.4282e-10, 6.4376e-10,
         6.4452e-10],
        ...,
        [2.9266e-09, 2.9268e-09, 2.9266e-09,  ..., 2.7580e-09, 2.7560e-09,
         2.7540e-09],
        [2.9275e-09, 2.9278e-09, 2.9279e-09,  ..., 2.7611e-09, 2.7592e-09,
         2.7572e-09],
        [2.9285e-09, 2.9287e-09, 2.9289e-09,  ..., 2.7643e-09, 2.7623e-09,
         2.7604e-09]], device='cuda:0')
pred : tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<SelectBackward0>)
y aggregation : tensor(6.9276e-07, device='cuda:0')
pred aggregation : tensor(0., device='cuda:0', grad_fn=<SumBackward1>)
gt : tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 8.5407e-12, 8.5359e-12,
         8.5215e-12],
        [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.0087e-11, 1.0123e-11,
         1.4727e-11],
        [1.0000e+00, 1.0000e+00, 1.0000e+00,  ..., 1.9761e-11, 1.9961e-11,
         2.0395e-11],
        ...,
        [1.0802e-10, 1.0588e-10, 1.0544e-10,  ..., 1.0725e-10, 1.0753e-10,
         1.0761e-10],
        [1.0749e-10, 1.0625e-10, 1.0577e-10,  ..., 1.0724e-10, 1.0765e-10,
         1.0776e-10],
        [1.0700e-10, 1.0638e-10, 1.0581e-10,  ..., 1.0719e-10, 1.0757e-10,
         1.0781e-10]], device='cuda:0')
pred : tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<SelectBackward0>)
y aggregation : tensor(189., device='cuda:0')
pred aggregation : tensor(0., device='cuda:0', grad_fn=<SumBackward1>)
gt : tensor([[3.8179e-10, 3.8188e-10, 3.8204e-10,  ..., 4.1535e-10, 4.1509e-10,
         4.1494e-10],
        [3.8275e-10, 3.8321e-10, 3.8320e-10,  ..., 4.1711e-10, 4.1665e-10,
         4.1632e-10],
        [3.8380e-10, 3.8428e-10, 3.8421e-10,  ..., 4.1862e-10, 4.1815e-10,
         4.1769e-10],
        ...,
        [8.1468e-10, 8.1447e-10, 8.1449e-10,  ..., 2.2250e-10, 2.2229e-10,
         2.2211e-10],
        [8.1537e-10, 8.1517e-10, 8.1530e-10,  ..., 2.2346e-10, 2.2329e-10,
         2.2303e-10],
        [8.1606e-10, 8.1587e-10, 8.1611e-10,  ..., 2.2408e-10, 2.2403e-10,
         2.2374e-10]], device='cuda:0')
pred : tensor([[0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        ...,
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.],
        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',
       grad_fn=<SelectBackward0>)
y aggregation : tensor(2.0065e-07, device='cuda:0')
pred aggregation : tensor(0., device='cuda:0', grad_fn=<SumBackward1>)
Traceback (most recent call last):
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\runpy.py", line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\runpy.py", line 110, in _get_module_details
    __import__(pkg_name)
  File "C:\Users\mhroh\Depth_Anything\src\train.py", line 65, in <module>
    loss.backward()
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\site-packages\torch\_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\site-packages\torch\autograd\__init__.py", line 347, in backward
    _engine_run_backward(
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\site-packages\torch\autograd\graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\runpy.py", line 187, in _run_module_as_main
    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\runpy.py", line 110, in _get_module_details
    __import__(pkg_name)
  File "C:\Users\mhroh\Depth_Anything\src\train.py", line 65, in <module>
    loss.backward()
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\site-packages\torch\_tensor.py", line 626, in backward
    torch.autograd.backward(
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\site-packages\torch\autograd\__init__.py", line 347, in backward
    _engine_run_backward(
  File "C:\Users\mhroh\anaconda3\envs\dl_env\lib\site-packages\torch\autograd\graph.py", line 823, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
