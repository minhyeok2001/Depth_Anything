Using cache found in /Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main
/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)
  warnings.warn("xFormers is not available (SwiGLU)")
/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)
  warnings.warn("xFormers is not available (Attention)")
/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)
  warnings.warn("xFormers is not available (Block)")
Using cache found in /Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main
Total parameters: 116806593
/Users/minhyeokroh/PycharmProjects/JupyterProject/models/Depth_Anything/src/train.py:158: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler()
/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.
  warnings.warn(
0it [00:00, ?it/s]/Users/minhyeokroh/PycharmProjects/JupyterProject/models/Depth_Anything/src/train.py:172: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
2
  with autocast(dtype=torch.bfloat16):
/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/amp/autocast_mode.py:266: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling
  warnings.warn(
torch.Size([2, 1024, 768])
gt ( 1st element ): tensor([1.0000, 1.0000, 1.0000,  ..., 0.0379, 0.0330, 0.0330])
pred ( 1st element ): tensor([0.1750, 0.1825, 0.1799,  ..., 0.1652, 0.1665, 0.1754],
       grad_fn=<SelectBackward0>)
y aggregation ( 1st element ): tensor(58369.7266)
pred aggregation ( 1st element ): tensor(38892.2773, grad_fn=<SumBackward1>)
Epoch [1/20], Batch [0], Loss: 3.3167
1it [00:48, 48.45s/it]
2
torch.Size([2, 1024, 768])
Traceback (most recent call last):
  File "<frozen runpy>", line 198, in _run_module_as_main
  File "<frozen runpy>", line 88, in _run_code
  File "/Users/minhyeokroh/PycharmProjects/JupyterProject/models/Depth_Anything/src/train.py", line 263, in <module>
    main()
  File "/Users/minhyeokroh/PycharmProjects/JupyterProject/models/Depth_Anything/src/train.py", line 260, in main
    train_student()
  File "/Users/minhyeokroh/PycharmProjects/JupyterProject/models/Depth_Anything/src/train.py", line 174, in train_student
    frozen_feature = frozen_model.get_intermediate_layers(inputs[B//3:(B//3)*2],n=1,return_class_token=False)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 309, in get_intermediate_layers
    outputs = self._get_intermediate_layers_not_chunked(x, n)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/models/vision_transformer.py", line 278, in _get_intermediate_layers_not_chunked
    x = blk(x)
        ^^^^^^
  File "/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py", line 254, in forward
    return super().forward(x_or_x_list)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py", line 113, in forward
    x = x + ffn_residual_func(x)
            ^^^^^^^^^^^^^^^^^^^^
  File "/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py", line 94, in ffn_residual_func
    return self.ls2(self.mlp(self.norm2(x)))
                    ^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/minhyeokroh/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/mlp.py", line 35, in forward
    x = self.fc1(x)
        ^^^^^^^^^^^
  File "/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/homebrew/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
